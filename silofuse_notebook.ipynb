{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T13:30:20.077373Z",
     "start_time": "2025-03-20T13:30:20.001071Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "sys.path.append(os.path.abspath('.')) # to run files that are away\n",
    "os.environ[\"WANDB_SILENT\"] = \"true\"  # Suppress WandB logs\n",
    "\n",
    "libraries = [\"torch\", \"numpy\", \"polars\"]\n",
    "modules   = {lib: sys.modules.get(lib) for lib in libraries}\n",
    "\n",
    "if not modules[\"torch\"]:\n",
    "    import torch\n",
    "if not modules[\"numpy\"]:\n",
    "    import numpy as np\n",
    "if not modules[\"polars\"]:\n",
    "    import polars as pl\n",
    "\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from autoencoder import Autoencoder, train_autoencoder, compute_reconstruction_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Loading the data\"\"\"\n",
    "\n",
    "with open('params.yaml', 'r') as file:\n",
    "    yaml_config = yaml.safe_load(file)\n",
    "\n",
    "data_file  = f\"./datasets/{yaml_config['dataset']['filename']}\"\n",
    "df         = pd.read_csv(data_file)\n",
    "\n",
    "X_scaled   = MinMaxScaler().fit_transform(df.values)\n",
    "X_tensor   = torch.tensor(X_scaled, dtype=torch.float32)\n",
    "dataset    = TensorDataset(X_tensor, X_tensor)  # Autoencoder reconstructs the input\n",
    "train_size = int(yaml_config['dataset']['train_valid_split'] * len(df))\n",
    "val_size   = len(df) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], training loss: 0.0315\n",
      "Validation loss: 0.0108\n",
      "Epoch [2/30], training loss: 0.0075\n",
      "Validation loss: 0.0063\n",
      "Epoch [3/30], training loss: 0.0062\n",
      "Validation loss: 0.0060\n",
      "Epoch [4/30], training loss: 0.0060\n",
      "Validation loss: 0.0061\n",
      "Epoch [5/30], training loss: 0.0059\n",
      "Validation loss: 0.0057\n",
      "Epoch [6/30], training loss: 0.0055\n",
      "Validation loss: 0.0049\n",
      "Epoch [7/30], training loss: 0.0048\n",
      "Validation loss: 0.0046\n",
      "Epoch [8/30], training loss: 0.0046\n",
      "Validation loss: 0.0046\n",
      "Epoch [9/30], training loss: 0.0046\n",
      "Validation loss: 0.0045\n",
      "Epoch [10/30], training loss: 0.0045\n",
      "Validation loss: 0.0044\n",
      "Epoch [11/30], training loss: 0.0045\n",
      "Validation loss: 0.0046\n",
      "Epoch [12/30], training loss: 0.0044\n",
      "Validation loss: 0.0043\n",
      "Epoch [13/30], training loss: 0.0044\n",
      "Validation loss: 0.0046\n",
      "Epoch [14/30], training loss: 0.0044\n",
      "Validation loss: 0.0043\n",
      "Epoch [15/30], training loss: 0.0043\n",
      "Validation loss: 0.0042\n",
      "Epoch [16/30], training loss: 0.0042\n",
      "Validation loss: 0.0041\n",
      "Epoch [17/30], training loss: 0.0039\n",
      "Validation loss: 0.0040\n",
      "Epoch [18/30], training loss: 0.0037\n",
      "Validation loss: 0.0036\n",
      "Epoch [19/30], training loss: 0.0037\n",
      "Validation loss: 0.0038\n",
      "Epoch [20/30], training loss: 0.0036\n",
      "Validation loss: 0.0038\n",
      "Epoch [21/30], training loss: 0.0036\n",
      "Validation loss: 0.0037\n",
      "Epoch [22/30], training loss: 0.0036\n",
      "Validation loss: 0.0037\n",
      "Epoch [23/30], training loss: 0.0036\n",
      "Validation loss: 0.0035\n",
      "Epoch [24/30], training loss: 0.0035\n",
      "Validation loss: 0.0035\n",
      "Epoch [25/30], training loss: 0.0035\n",
      "Validation loss: 0.0035\n",
      "Epoch [26/30], training loss: 0.0035\n",
      "Validation loss: 0.0035\n",
      "Epoch [27/30], training loss: 0.0035\n",
      "Validation loss: 0.0036\n",
      "Epoch [28/30], training loss: 0.0035\n",
      "Validation loss: 0.0034\n",
      "Epoch [29/30], training loss: 0.0035\n",
      "Validation loss: 0.0034\n",
      "Epoch [30/30], training loss: 0.0035\n",
      "Validation loss: 0.0035\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Autoencoder training\"\"\"\n",
    "\n",
    "hidden_dim       = yaml_config['autoencoder_design']['hidden_dim']\n",
    "encoding_dim     = yaml_config['autoencoder_design']['encoding_dim']\n",
    "latent_dim       = yaml_config['autoencoder_design']['latent_dim']\n",
    "dropout_prob     = yaml_config['autoencoder_design']['dropout_prob']\n",
    "training_epochs  = yaml_config['autoencoder_training']['training_epochs']\n",
    "batch_size       = yaml_config['autoencoder_training']['batch_size']\n",
    "optimizer_lr     = yaml_config['autoencoder_training']['optimizer_lr']\n",
    "weight_decay     = yaml_config['autoencoder_training']['weight_decay']\n",
    "training_patience= yaml_config['autoencoder_training']['training_patience']\n",
    "\n",
    "# Create DataLoader objects for train and validation datasets\n",
    "input_size   = X_scaled.shape[1]\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "autoencoder  = Autoencoder(input_size, hidden_dim, encoding_dim, latent_dim, dropout_prob)\n",
    "optimizer    = torch.optim.AdamW(autoencoder.parameters(), lr=optimizer_lr, weight_decay=weight_decay)\n",
    "\n",
    "train_autoencoder(autoencoder, training_epochs, train_loader, optimizer,\n",
    "                  validation_loader=val_loader, patience = training_patience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Run AE on new dataset\\nCan be for reconstruction, anomaly detection, feature extraction, classification'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Run AE on new dataset\n",
    "Can be for reconstruction, anomaly detection, feature extraction, classification\"\"\"\n",
    "\n",
    "# PAUSED, WILL PICK UP LATER\n",
    "\n",
    "# autoencoder.eval()  # Set the model to evaluation mode (disables dropout)\n",
    "\n",
    "# with torch.no_grad():  # No gradient computation during inference\n",
    "#     x_input = torch.tensor(new_data, dtype=torch.float32)  # New data input\n",
    "#     x_reconstructed = autoencoder(x_input)  # Reconstruct input\n",
    "\n",
    "# reconstruction_error = compute_reconstruction_loss(x_input, x_reconstructed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_tensor.shape=torch.Size([19735, 28, 1])\n",
      "conv_block: in_channels = 28, out_channels = 18\n",
      "conv_block: in_channels = 18, out_channels = 36\n",
      "conv_block: in_channels = 36, out_channels = 72\n",
      "conv_block: in_channels = 72, out_channels = 36\n",
      "conv_block: in_channels = 36, out_channels = 18\n",
      "Epoch [1/4], Loss: 0.9847, Val Loss: 0.9512\n",
      "Epoch [2/4], Loss: 0.9499, Val Loss: 0.9316\n",
      "Epoch [3/4], Loss: 0.9345, Val Loss: 0.9196\n",
      "Epoch [4/4], Loss: 0.9299, Val Loss: 0.9083\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Diffusion training\"\"\"\n",
    "\n",
    "import diffusion_model as diff\n",
    "\n",
    "diff_steps       = yaml_config['diffusion_design']['diff_steps']\n",
    "cos_start_offset = yaml_config['noise_scheduler']['cos_start_offset']\n",
    "noise_profile    = yaml_config['noise_scheduler']['noise_profile']\n",
    "start_noise_val  = yaml_config['noise_scheduler']['start_noise_val']\n",
    "end_noise_val    = yaml_config['noise_scheduler']['end_noise_val']\n",
    "train_epochs     = yaml_config['diffusion_training']['train_epochs']\n",
    "training_patience= yaml_config['diffusion_training']['training_patience']\n",
    "optimizer_lr     = yaml_config['diffusion_training']['optimizer_lr']\n",
    "weight_decay     = yaml_config['diffusion_training']['weight_decay']\n",
    "base_channels    = yaml_config['Unet_design']['base_channels']\n",
    "dropout_prob     = yaml_config['Unet_design']['dropout_prob']\n",
    "\n",
    "X_tensor = torch.tensor(X_scaled, dtype=torch.float32).unsqueeze(-1)  # [B, 1, L]\n",
    "print(f\"{X_tensor.shape=}\")\n",
    "\n",
    "betas = diff.get_noise_schedule(start_val=start_noise_val, end_val=end_noise_val, diff_steps=diff_steps,\n",
    "                                cos_start_offset=cos_start_offset, noise_profile=noise_profile)\n",
    "diffusion_model = diff.UNet(X_tensor.shape[1], dropout_prob, base_channels)\n",
    "optimizer       = torch.optim.AdamW(diffusion_model.parameters(), lr=optimizer_lr, weight_decay=weight_decay)\n",
    "\n",
    "diff.train_diffusion(diffusion_model, train_loader, optimizer, betas,\n",
    "                     diff_steps, train_epochs, val_loader, training_patience)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is this working?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
