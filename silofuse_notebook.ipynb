{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T13:30:20.077373Z",
     "start_time": "2025-03-20T13:30:20.001071Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "sys.path.append(os.path.abspath('.')) # to run files that are away\n",
    "os.environ[\"WANDB_SILENT\"] = \"true\"  # Suppress WandB logs\n",
    "\n",
    "libraries = [\"torch\", \"numpy\", \"polars\"]\n",
    "modules   = {lib: sys.modules.get(lib) for lib in libraries}\n",
    "\n",
    "if not modules[\"torch\"]:\n",
    "    import torch\n",
    "if not modules[\"numpy\"]:\n",
    "    import numpy as np\n",
    "if not modules[\"polars\"]:\n",
    "    import polars as pl\n",
    "\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Loading the data\"\"\"\n",
    "\n",
    "with open('params.yaml', 'r') as file:\n",
    "    yaml_config = yaml.safe_load(file)\n",
    "\n",
    "data_file  = f\"./datasets/{yaml_config['dataset']['filename']}\"\n",
    "df         = pd.read_csv(data_file)\n",
    "\n",
    "X_scaled   = MinMaxScaler().fit_transform(df.values)\n",
    "X_tensor   = torch.tensor(X_scaled, dtype=torch.float32)\n",
    "dataset    = TensorDataset(X_tensor, X_tensor)  # Autoencoder reconstructs the input\n",
    "train_size = int(yaml_config['dataset']['train_valid_split'] * len(df))\n",
    "val_size   = len(df) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Using device from module: cuda\n",
      "Epoch [1/30], training loss: 0.1546\n",
      "Validation loss: 0.0291\n",
      "Epoch [2/30], training loss: 0.0514\n",
      "Validation loss: 0.0089\n",
      "Epoch [3/30], training loss: 0.0249\n",
      "Validation loss: 0.0034\n",
      "Epoch [4/30], training loss: 0.0150\n",
      "Validation loss: 0.0018\n",
      "Epoch [5/30], training loss: 0.0099\n",
      "Validation loss: 0.0010\n",
      "Epoch [6/30], training loss: 0.0068\n",
      "Validation loss: 0.0006\n",
      "Epoch [7/30], training loss: 0.0048\n",
      "Validation loss: 0.0004\n",
      "Epoch [8/30], training loss: 0.0035\n",
      "Validation loss: 0.0002\n",
      "Epoch [9/30], training loss: 0.0024\n",
      "Validation loss: 0.0002\n",
      "Epoch [10/30], training loss: 0.0017\n",
      "Validation loss: 0.0001\n",
      "Epoch [11/30], training loss: 0.0011\n",
      "Validation loss: 0.0001\n",
      "Epoch [12/30], training loss: 0.0008\n",
      "Validation loss: 0.0000\n",
      "Epoch [13/30], training loss: 0.0005\n",
      "Validation loss: 0.0000\n",
      "Epoch [14/30], training loss: 0.0003\n",
      "Validation loss: 0.0000\n",
      "Epoch [15/30], training loss: 0.0002\n",
      "Validation loss: 0.0000\n",
      "Epoch [16/30], training loss: 0.0001\n",
      "Validation loss: 0.0000\n",
      "Epoch [17/30], training loss: 0.0001\n",
      "Validation loss: 0.0000\n",
      "Epoch [18/30], training loss: 0.0000\n",
      "Validation loss: 0.0000\n",
      "Epoch [19/30], training loss: 0.0000\n",
      "Validation loss: 0.0000\n",
      "Epoch [20/30], training loss: 0.0000\n",
      "Validation loss: 0.0000\n",
      "Epoch [21/30], training loss: 0.0000\n",
      "Validation loss: 0.0000\n",
      "Epoch [22/30], training loss: 0.0000\n",
      "Validation loss: 0.0000\n",
      "Epoch [23/30], training loss: 0.0000\n",
      "Validation loss: 0.0000\n",
      "Epoch [24/30], training loss: 0.0000\n",
      "Validation loss: 0.0000\n",
      "Epoch [25/30], training loss: 0.0000\n",
      "Validation loss: 0.0000\n",
      "Epoch [26/30], training loss: 0.0000\n",
      "Validation loss: 0.0000\n",
      "Epoch [27/30], training loss: 0.0000\n",
      "Validation loss: 0.0000\n",
      "Epoch [28/30], training loss: 0.0000\n",
      "Validation loss: 0.0000\n",
      "Epoch [29/30], training loss: 0.0000\n",
      "Validation loss: 0.0000\n",
      "Epoch [30/30], training loss: 0.0000\n",
      "Validation loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Autoencoder training\"\"\"\n",
    "\n",
    "import autoencoder as ae\n",
    "# from autoencoder import Autoencoder, train_autoencoder\n",
    "\n",
    "hidden_dim        = yaml_config['autoencoder_design']['hidden_dim']\n",
    "encoding_dim      = yaml_config['autoencoder_design']['encoding_dim']\n",
    "latent_dim        = yaml_config['autoencoder_design']['latent_dim']\n",
    "dropout_prob      = yaml_config['autoencoder_design']['dropout_prob']\n",
    "training_epochs   = yaml_config['autoencoder_training']['training_epochs']\n",
    "batch_size        = yaml_config['autoencoder_training']['batch_size']\n",
    "optimizer_lr      = yaml_config['autoencoder_training']['optimizer_lr']\n",
    "weight_decay      = yaml_config['autoencoder_training']['weight_decay']\n",
    "training_patience = yaml_config['autoencoder_training']['training_patience']\n",
    "scheduler_patience= yaml_config['autoencoder_training']['scheduler_patience']\n",
    "scheduler_mode    = yaml_config['autoencoder_training']['scheduler_mode']\n",
    "scheduler_factor  = yaml_config['autoencoder_training']['scheduler_factor']\n",
    "\n",
    "device = ae.device\n",
    "print(f\"Using device from module: {device}\")\n",
    "\n",
    "# Create DataLoader objects for train and validation datasets\n",
    "input_size   = X_scaled.shape[1]\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "autoencoder  = ae.Autoencoder(input_size, hidden_dim, encoding_dim, latent_dim, dropout_prob)\n",
    "optimizer    = torch.optim.AdamW(autoencoder.parameters(), lr=optimizer_lr, weight_decay=weight_decay)\n",
    "scheduler    = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, scheduler_mode, patience=scheduler_patience, factor=scheduler_factor)\n",
    "\n",
    "ae.train_autoencoder(device, autoencoder, training_epochs, train_loader, optimizer, scheduler,\n",
    "                     validation_loader=val_loader, patience = training_patience)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Run AE on new dataset\\nCan be for reconstruction, anomaly detection, feature extraction, classification'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Run AE on new dataset\n",
    "Can be for reconstruction, anomaly detection, feature extraction, classification\"\"\"\n",
    "\n",
    "# PAUSED, WILL PICK UP LATER\n",
    "\n",
    "# autoencoder.eval()  # Set the model to evaluation mode (disables dropout)\n",
    "\n",
    "# with torch.no_grad():  # No gradient computation during inference\n",
    "#     x_input = torch.tensor(new_data, dtype=torch.float32)  # New data input\n",
    "#     x_reconstructed = autoencoder(x_input)  # Reconstruct input\n",
    "\n",
    "# reconstruction_error = compute_reconstruction_loss(x_input, x_reconstructed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Using device from module: cuda\n",
      "X_tensor.shape=torch.Size([19735, 28, 1])\n",
      "conv_block: in_channels = 28, out_channels = 64\n",
      "conv_block: in_channels = 64, out_channels = 128\n",
      "conv_block: in_channels = 128, out_channels = 256\n",
      "conv_block: in_channels = 256, out_channels = 128\n",
      "conv_block: in_channels = 128, out_channels = 64\n",
      "Epoch [1/100], loss: 0.8332, Validation loss: 0.6627\n",
      "Epoch [2/100], loss: 0.7052, Validation loss: 0.5734\n",
      "Epoch [3/100], loss: 0.6679, Validation loss: 0.5392\n",
      "Epoch [4/100], loss: 0.6503, Validation loss: 0.5358\n",
      "Epoch [5/100], loss: 0.6391, Validation loss: 0.5215\n",
      "Epoch [6/100], loss: 0.6398, Validation loss: 0.5223\n",
      "Epoch [7/100], loss: 0.6341, Validation loss: 0.5133\n",
      "Epoch [8/100], loss: 0.6306, Validation loss: 0.5165\n",
      "Epoch [9/100], loss: 0.6265, Validation loss: 0.5036\n",
      "Epoch [10/100], loss: 0.6251, Validation loss: 0.4987\n",
      "Epoch [11/100], loss: 0.6220, Validation loss: 0.4970\n",
      "Epoch [12/100], loss: 0.6228, Validation loss: 0.4895\n",
      "Epoch [13/100], loss: 0.6201, Validation loss: 0.4955\n",
      "Epoch [14/100], loss: 0.6163, Validation loss: 0.4908\n",
      "Epoch [15/100], loss: 0.6162, Validation loss: 0.5015\n",
      "Epoch [16/100], loss: 0.6167, Validation loss: 0.4938\n",
      "Epoch [17/100], loss: 0.6176, Validation loss: 0.4891\n",
      "Epoch [18/100], loss: 0.6131, Validation loss: 0.4894\n",
      "Epoch [19/100], loss: 0.6142, Validation loss: 0.4886\n",
      "Epoch [20/100], loss: 0.6113, Validation loss: 0.4946\n",
      "Epoch [21/100], loss: 0.6123, Validation loss: 0.4893\n",
      "Epoch [22/100], loss: 0.6085, Validation loss: 0.4904\n",
      "Epoch [23/100], loss: 0.6083, Validation loss: 0.4794\n",
      "Epoch [24/100], loss: 0.6108, Validation loss: 0.4809\n",
      "Epoch [25/100], loss: 0.6104, Validation loss: 0.4749\n",
      "Epoch [26/100], loss: 0.6057, Validation loss: 0.4866\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m optimizer       \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdamW(diffusion_model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39moptimizer_lr, weight_decay\u001b[38;5;241m=\u001b[39mweight_decay)\n\u001b[1;32m     30\u001b[0m scheduler       \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mCosineAnnealingLR(optimizer, T_max\u001b[38;5;241m=\u001b[39mtrain_epochs)\n\u001b[0;32m---> 32\u001b[0m \u001b[43mdiff\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_diffusion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiffusion_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbetas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mdiff_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_patience\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/silofuse_timeseries/diffusion_model.py:292\u001b[0m, in \u001b[0;36mtrain_diffusion\u001b[0;34m(device, model, train_loader, optimizer, scheduler, betas, diffusion_steps, epochs, validation_loader, patience)\u001b[0m\n\u001b[1;32m    289\u001b[0m num_channels \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;241m.\u001b[39min_channels \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model\u001b[38;5;241m.\u001b[39moutput, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124min_channels\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m model\u001b[38;5;241m.\u001b[39mdown1[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39min_channels\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m--> 292\u001b[0m     avg_loss \u001b[38;5;241m=\u001b[39m \u001b[43m_train_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbetas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiffusion_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_channels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m], loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m validation_loader:\n",
      "File \u001b[0;32m~/projects/silofuse_timeseries/diffusion_model.py:250\u001b[0m, in \u001b[0;36m_train_epoch\u001b[0;34m(model, train_loader, optimizer, betas, diffusion_steps, device, num_channels)\u001b[0m\n\u001b[1;32m    248\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    249\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m--> 250\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclip_grad_norm_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_norm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# prevents exploding gradients\u001b[39;00m\n\u001b[1;32m    251\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    253\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m x_0\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/silofuse_env/lib/python3.10/site-packages/torch/nn/utils/clip_grad.py:38\u001b[0m, in \u001b[0;36m_no_grad.<locals>._no_grad_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_no_grad_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 38\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/silofuse_env/lib/python3.10/site-packages/torch/nn/utils/clip_grad.py:219\u001b[0m, in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type, error_if_nonfinite, foreach)\u001b[0m\n\u001b[1;32m    217\u001b[0m     parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(parameters)\n\u001b[1;32m    218\u001b[0m grads \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m parameters \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[0;32m--> 219\u001b[0m total_norm \u001b[38;5;241m=\u001b[39m \u001b[43m_get_total_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_if_nonfinite\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m _clip_grads_with_norm_(parameters, max_norm, total_norm, foreach)\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_norm\n",
      "File \u001b[0;32m~/miniconda3/envs/silofuse_env/lib/python3.10/site-packages/torch/nn/utils/clip_grad.py:38\u001b[0m, in \u001b[0;36m_no_grad.<locals>._no_grad_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_no_grad_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 38\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/silofuse_env/lib/python3.10/site-packages/torch/nn/utils/clip_grad.py:91\u001b[0m, in \u001b[0;36m_get_total_norm\u001b[0;34m(tensors, norm_type, error_if_nonfinite, foreach)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (device, _), ([device_tensors], _) \u001b[38;5;129;01min\u001b[39;00m grouped_tensors\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (foreach \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m _has_foreach_support(device_tensors, device)) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m     89\u001b[0m         foreach \u001b[38;5;129;01mand\u001b[39;00m _device_has_foreach_support(device)\n\u001b[1;32m     90\u001b[0m     ):\n\u001b[0;32m---> 91\u001b[0m         norms\u001b[38;5;241m.\u001b[39mextend(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_foreach_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm_type\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m foreach:\n\u001b[1;32m     93\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     94\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforeach=True was passed, but can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt use the foreach API on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tensors\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     95\u001b[0m         )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"Diffusion training\"\"\"\n",
    "\n",
    "import diffusion_model as diff\n",
    "\n",
    "diff_steps        = yaml_config['diffusion_design']['diff_steps']\n",
    "cos_start_offset  = yaml_config['noise_scheduler']['cos_start_offset']\n",
    "noise_profile     = yaml_config['noise_scheduler']['noise_profile']\n",
    "start_noise_val   = yaml_config['noise_scheduler']['start_noise_val']\n",
    "end_noise_val     = yaml_config['noise_scheduler']['end_noise_val']\n",
    "train_epochs      = yaml_config['diffusion_training']['train_epochs']\n",
    "training_patience = yaml_config['diffusion_training']['training_patience']\n",
    "optimizer_lr      = yaml_config['diffusion_training']['optimizer_lr']\n",
    "weight_decay      = yaml_config['diffusion_training']['weight_decay']\n",
    "scheduler_patience= yaml_config['diffusion_training']['scheduler_patience']\n",
    "scheduler_mode    = yaml_config['diffusion_training']['scheduler_mode']\n",
    "scheduler_factor  = yaml_config['diffusion_training']['scheduler_factor']\n",
    "base_channels     = yaml_config['Unet_design']['base_channels']\n",
    "dropout_prob      = yaml_config['Unet_design']['dropout_prob']\n",
    "\n",
    "device = diff.device\n",
    "print(f\"Using device from module: {device}\")\n",
    "\n",
    "X_tensor = torch.tensor(X_scaled, dtype=torch.float32).unsqueeze(-1)  # [B, 1, L]\n",
    "print(f\"{X_tensor.shape=}\")\n",
    "\n",
    "betas = diff.get_noise_schedule(start_val=start_noise_val, end_val=end_noise_val, diff_steps=diff_steps,\n",
    "                                cos_start_offset=cos_start_offset, noise_profile=noise_profile)\n",
    "diffusion_model = diff.UNet(X_tensor.shape[1], dropout_prob, base_channels)\n",
    "optimizer       = torch.optim.AdamW(diffusion_model.parameters(), lr=optimizer_lr, weight_decay=weight_decay)\n",
    "scheduler       = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=train_epochs)\n",
    "\n",
    "diff.train_diffusion(device, diffusion_model, train_loader, optimizer, scheduler, betas,\n",
    "                     diff_steps, train_epochs, val_loader, training_patience)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is this working?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "silofuse_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
